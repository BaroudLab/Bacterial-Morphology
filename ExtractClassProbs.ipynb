{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleClassAnalysis(chip,class_name):\n",
    "    chip = chip.rename(columns={class_name: 'neg'})\n",
    "    \n",
    "    chip.neg=chip.neg.replace({1: 0, 0: 1}) # we switch so we can simply use the mean\n",
    "    prob_neg=chip.neg.mean()\n",
    "\n",
    " \n",
    "    #now all chip information\n",
    "    out=pd.DataFrame({'prob_neg_label':prob_neg,'prob_pos_label':1-prob_neg,'total_label':len(chip.neg.values)},index=[0])    \n",
    "    out=out.add_suffix(f'_{class_name}')\n",
    "    \n",
    "    return out\n",
    "\n",
    "def AnalyseChipClasses(chip,classes=['positive','rods','filaments','planktonic','clumped']):\n",
    "    \n",
    "    collect=[]\n",
    "    for c in classes:\n",
    "            collect.append(SingleClassAnalysis(chip[[c]],c))\n",
    "\n",
    "    df = reduce(lambda df1,df2: df1.join(df2), collect)\n",
    "    df=df.reset_index(drop=True)\n",
    "    df['concentration']=chip['concentration'].values[0] # we groupy chip when we apply this function so only one concentration\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Extract class probabilities from labeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder='PredictedLabelsTables/' \n",
    "\n",
    "paths=glob.glob(f'{Folder}*_trained.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## unconditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "\n",
    "    data = pd.read_csv(f'{p}',index_col=0)\n",
    "    data['n_cells_1']=data.n_cells_1.astype(int)\n",
    "    data['n_cells_2']=data.n_cells_2.astype(int)\n",
    "    classes=['rods','filaments','planktonic','clumped']\n",
    "    for c in classes:\n",
    "        data[c]=data[c].astype(int)\n",
    "    chip_info=[]\n",
    "    chip_info=data.groupby(['chip']).apply(lambda x: AnalyseChipClasses(x),include_groups=False)\n",
    "    chip_info=chip_info.droplevel(level=1)\n",
    "    chip_info=chip_info.reset_index()\n",
    "    Filename=p.split('/')[1].split('_trained')[0]\n",
    "\n",
    "    chip_info.to_csv(f'{Folder}chip_info_{Filename}_prob.csv')\n",
    "    print(f'save done {p}',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## positive i.e. observing succesful growth and morphology: in unification we compute the actualy conditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "\n",
    "    data = pd.read_csv(f'{p}',index_col=0)\n",
    "    data['n_cells_1']=data.n_cells_1.astype(int)\n",
    "    data['n_cells_2']=data.n_cells_2.astype(int)\n",
    "    classes=['rods','filaments','planktonic','clumped']\n",
    "    for c in classes:\n",
    "        data[c]=data[[c,'positive']].all(axis=1) # positive and morphology\n",
    "        data[c]=data[c].astype(int)\n",
    "\n",
    "    chip_info=[]\n",
    "    chip_info=data.groupby(['chip']).apply(lambda x: AnalyseChipClasses(x),include_groups=False)\n",
    "    chip_info=chip_info.droplevel(level=1)\n",
    "    chip_info=chip_info.reset_index()\n",
    "    Filename=p.split('/')[1].split('_trained')[0]\n",
    "\n",
    "    chip_info.to_csv(f'{Folder}chip_info_{Filename}_prob_and_pos.csv')\n",
    "    print(f'save done {p}',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Unify tables: warning overwrites provided data\n",
    "this creastes the table present in the github repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionise_datasets(data, dates, date_index):\n",
    "    \"\"\"Combine datasets\"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for i, df in enumerate(data):\n",
    "        df_copy = df.copy()\n",
    "        df_copy['dataset'] = i\n",
    "        df_copy['date'] = dates[i]\n",
    "        df_copy['date_index'] = date_index[i]\n",
    "        result.append(df_copy)\n",
    "\n",
    "\n",
    "    out=pd.concat(result, ignore_index=True)\n",
    "    out = out.sort_values('concentration').reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder='PredictedLabelsTables/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Genta ---------------------------------------------------------------------\n",
    "dates=['20221101','20221101','20230110','20230110'] # we add this metadata to keep track of the experiments\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta2_prob.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta-2_prob.csv',index_col=0))\n",
    "\n",
    "df=  unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Gentamicin.csv')  #warning overwrites provided data\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta2_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta-2_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "df=  unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'tables/probability_tables/Gentamicin_cond_pos.csv')  #warning overwrites provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Tetra---------------------------------------------------------------------\n",
    "dates=['20230315','20230315','20230404','20230404']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-2_prob.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set2_prob.csv',index_col=0))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Tetracycline.csv')  #warning overwrites provided data\n",
    "\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-2_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set2_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "df=unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'tables/probability_tables/Tetracycline_cond_pos.csv')  #warning overwrites provided data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Cipro---------------------------------------------------------------------\n",
    "dates=['20220531','20220531','20230131','20230131']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro_1stexp_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro_2ndexp_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-2_prob.csv',index_col=0))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Ciprofloxacin.csv')  #warning overwrites provided data\n",
    "\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro_1stexp_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro_2ndexp_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-2_prob.csv',index_col=0))\n",
    "\n",
    "\n",
    "\n",
    "df=unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'tables/probability_tables/Ciprofloxacin_cond_pos.csv')  #warning overwrites provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------AMP---------------------------------------------------------------------\n",
    "dates=['20220614','20220614']\n",
    "date_index=[1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-2_prob.csv',index_col=0))\n",
    "\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Ampicilin.csv')  #warning overwrites provided data\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-2_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "\n",
    "df=unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'tables/probability_tables/Ampicilin_cond_pos.csv')  #warning overwrites provided data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------CHP---------------------------------------------------------------------\n",
    "dates=['20220524','20220602','20220628','20220628','20221012','20221013','20221031','20221031','20221122','20230111','20230111','20230221','20230313','20230313']\n",
    "date_index=[1,1,1,2,1,1,1,2,1,1,2,1,1,2]\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220524-MIC-e.coli-chp-LB_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220602-MIC-e.coli-chp-LB_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-2_prob.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221012-ecoli-chp_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221013-ecoli-chp_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp2_prob.csv',index_col=0)) # A lot of empty wells which becomes positive (more than 50%) ==> Data not trustworthy for 0ug and 2ug, the rest all dead so we can't say much\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221122-ecoli-chp_prob.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp-2_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230221-ecoli-chp-1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-1_prob.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-2_prob.csv',index_col=0))\n",
    "\n",
    "df= unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Chloramphenicol.csv')  #warning overwrites provided data\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220524-MIC-e.coli-chp-LB_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220602-MIC-e.coli-chp-LB_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-2_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221012-ecoli-chp_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221013-ecoli-chp_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp2_prob_and_pos.csv',index_col=0)) # A lot of empty wells which becomes positive (more than 50%) ==> Data not trustworthy for 0ug and 2ug, the rest all dead so we can't say much\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221122-ecoli-chp_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp-2_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230221-ecoli-chp-1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-1_prob_and_pos.csv',index_col=0))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-2_prob_and_pos.csv',index_col=0))\n",
    "\n",
    "\n",
    "\n",
    "df= unionise_datasets(data_and_pos,dates,date_index)\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'tables/probability_tables/Chloramphenicol_cond_pos.csv')  #warning overwrites provided data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
