{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522ecc3d-d77f-4ea0-b92b-4f925d7fdb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emaikran/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8cd056f8-feb2-4b15-8cca-2bba8807577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleClassAnalysis(chip,class_name):\n",
    "    chip = chip.rename(columns={class_name: 'neg'})\n",
    "    \n",
    "    chip.neg=chip.neg.replace({1: 0, 0: 1}) # we switch so we can simply use the mean\n",
    "    prob_neg=chip.neg.mean()\n",
    "\n",
    " \n",
    "    #now all chip information\n",
    "    out=pd.DataFrame({'prob_neg_label':prob_neg,'prob_pos_label':1-prob_neg,'total_label':len(chip.neg.values)},index=[0])    \n",
    "    out=out.add_suffix(f'_{class_name}')\n",
    "    \n",
    "    return out\n",
    "\n",
    "def AnalyseChipClasses(chip,classes=['positive','rods','filaments','planktonic','clumped']):\n",
    "    \n",
    "    collect=[]\n",
    "    for c in classes:\n",
    "            collect.append(SingleClassAnalysis(chip[[c]],))\n",
    "\n",
    "    df = reduce(lambda df1,df2: df1.join(df2), collect)\n",
    "    df=df.reset_index(drop=True)\n",
    "    df['concentration']=chip['concentration'].values[0] # we groupy chip when we apply this function so only one concentration\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b9abb-9062-4a2f-b61a-9863f36f240b",
   "metadata": {},
   "source": [
    "# Extract class probabilities from labeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aceed41-2a72-469a-851f-8b1c7b4e77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Folder='PredictedLabelsTables/' \n",
    "\n",
    "paths=glob.glob(f'{Folder}*_trained.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e48452-1ce2-4c9c-b06b-4497a6e5144f",
   "metadata": {},
   "source": [
    "## unconditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad0a1ce-6f8a-4a4a-a6f6-7448f03bc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "\n",
    "    data = pd.read_csv(f'{p}',index_col=0)\n",
    "    data['n_cells_1']=data.n_cells_1.astype(int)\n",
    "    data['n_cells_2']=data.n_cells_2.astype(int)\n",
    "    classes=['rods','filaments','planktonic','clumped']\n",
    "    for c in classes:\n",
    "        data[c]=data[c].astype(int)\n",
    "    chip_info=[]\n",
    "    chip_info=data.groupby(['chip']).apply(lambda x: AnalyseChipClasses(x))\n",
    "    chip_info=chip_info.droplevel(level=1)\n",
    "    chip_info=chip_info.reset_index()\n",
    "    Filename=p.split('/')[1].split('_trained')[0]\n",
    "\n",
    "    chip_info.to_csv(f'{Folder}chip_info_{Filename}_prob.csv')\n",
    "    print('save done',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e406bdb7-49ba-4df6-899f-fdcf2f8f3d38",
   "metadata": {},
   "source": [
    "## positive i.e. observing succesful growth and morphology: in unification we compute the actualy conditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c07f77-44b9-470c-b2d1-414bdb24f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "\n",
    "    data = pd.read_csv(f'{p}',index_col=0)\n",
    "    data['n_cells_1']=data.n_cells_1.astype(int)\n",
    "    data['n_cells_2']=data.n_cells_2.astype(int)\n",
    "    classes=['rods','filaments','planktonic','clumped']\n",
    "    for c in classes:\n",
    "        data[c]=data[[c,'positive']].all(axis=1) # positive and morphology\n",
    "        data[c]=data[c].astype(int)\n",
    "    data.drop(data[data.positive==False].index,inplace=True) # remove data that was not positive because we condition on it\n",
    "    data=data.reset_index()\n",
    "    chip_info=[]\n",
    "    chip_info=data.groupby(['chip']).apply(lambda x: AnalyseChipClasses(x))\n",
    "    chip_info=chip_info.droplevel(level=1)\n",
    "    chip_info=chip_info.reset_index()\n",
    "    Filename=p.split('/')[1].split('_trained')[0]\n",
    "\n",
    "    chip_info.to_csv(f'{Folder}chip_info_{Filename}_prob_and_pos.csv')\n",
    "    print('save done',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fbb9b-1848-4496-8e94-c6467ce9c478",
   "metadata": {},
   "source": [
    "# Unify tables\n",
    "this creastes the table present in the github \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97168f4-1743-487d-8ee6-0d8369f89d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionise_datasets(data, dates, date_index):\n",
    "    \"\"\"Combine datasets\"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for i, df in enumerate(data):\n",
    "        df_copy = df.copy()\n",
    "        df_copy['dataset'] = i\n",
    "        df_copy['date'] = dates[i]\n",
    "        df_copy['date_index'] = date_index[i]\n",
    "        result.append(df_copy)\n",
    "    \n",
    "    return pd.concat(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d6a0d-295e-4e1c-becb-492b63efd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder='PredictedLabelsTables/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0a744-c9c8-4e10-b580-ab0acd17bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Genta---------------------------------------------------------------------\n",
    "dates=['20221101','20221101','20230110','20230110'] # we add this metadata to keep track of the experiments\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta2_prob.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta-2_prob.csv'))\n",
    "\n",
    "df=  unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Gentamicin.csv')\n",
    "\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221101-ecoli-genta2_prob_and_pos.csv'))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230110-e.coli-genta-2_prob_and_pos.csv'))\n",
    "\n",
    "df=  unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'../tables/probability_tables/Gentamicin_cond_pos.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d124a-251d-4952-b8f4-039aaadabf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Tetra---------------------------------------------------------------------\n",
    "dates=['20230315','20230315','20230404','20230404']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-2_prob.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set2_prob.csv'))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Tetracycline.csv')\n",
    "\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230315-ecoli_set-2_prob_and_pos.csv'))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230404-ecoli-Tetracycline_set2_prob_and_pos.csv'))\n",
    "\n",
    "df=unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'../tables/probability_tables/Tetracycline_cond_pos.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9fd32-4f83-49f1-ab0a-9c1f6baeed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Cipro---------------------------------------------------------------------\n",
    "dates=['20220531','20220531','20230131','20230131']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro-1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro-2_prob.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-1stexp_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-2ndexp_prob.csv'))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Ciprofloxacin.csv')\n",
    "\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro-1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220531-MIC-e.coli-cipro-2_prob_and_pos.csv'))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-1stexp_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230131-ecoli-cipro-2ndexp_prob_and_pos.csv'))\n",
    "\n",
    "df=unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'../tables/probability_tables/Ciprofloxacin_cond_pos.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ef4e0-c375-4e21-ab3a-1de296833a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------AMP---------------------------------------------------------------------\n",
    "dates=['20220614','20220614']\n",
    "date_index=[1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-2_prob.csv'))\n",
    "\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Ampicilin.csv')\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220614-MIC-e.coli-amp-LB-2_prob_and_pos.csv'))\n",
    "\n",
    "\n",
    "df=unionise_datasets(data_and_pos,dates,date_index)\n",
    "\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'../tables/probability_tables/Ampicilin_cond_pos.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64362087-02ae-441b-ac36-86a26434809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------CHP---------------------------------------------------------------------\n",
    "dates=['20220524','20220602','20220628','20220628','20221012','20221013','20221031','20221031','20221122','20230111','20230111','20230221','20230313','20230313']\n",
    "date_index=[1,1,1,2,1,1,1,2,1,1,2,1,1,2]\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220524-MIC-e.coli-chp-LB_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220602-MIC-e.coli-chp-LB_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-2_prob.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221012-ecoli-chp_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221013-ecoli-chp_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp2_prob.csv')) # A lot of empty wells which becomes positive (more than 50%) ==> Data not trustworthy for 0ug and 2ug, the rest all dead so we can't say much\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20221122-ecoli-chp_prob.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp-2_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230221-ecoli-chp-1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-1_prob.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-2_prob.csv'))\n",
    "\n",
    "df= unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Chloramphenicol.csv')\n",
    "\n",
    "data_and_pos=[]\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220524-MIC-e.coli-chp-LB_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220602-MIC-e.coli-chp-LB_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20220628-MIC-e.coli-chp-LB-2_prob_and_pos.csv'))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221012-ecoli-chp_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221013-ecoli-chp_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221031-ecoli-chp2_prob_and_pos.csv')) # A lot of empty wells which becomes positive (more than 50%) ==> Data not trustworthy for 0ug and 2ug, the rest all dead so we can't say much\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20221122-ecoli-chp_prob_and_pos.csv'))\n",
    "\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230111-ecoli-chp-2_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230221-ecoli-chp-1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-1_prob_and_pos.csv'))\n",
    "data_and_pos.append(pd.read_csv(f'{Folder}chip_info_20230313-ecoli-chp-2_prob_and_pos.csv'))\n",
    "\n",
    "\n",
    "\n",
    "df= unionise_datasets(data_and_pos,dates,date_index)\n",
    "# calculate condionals\n",
    "for l  in ['rods','planktonic','filaments','clumped']:\n",
    "    df[f'prob_pos_label_{l}']=df[f'prob_pos_label_{l}']/df[f'prob_pos_label_positive']\n",
    "    \n",
    "df.to_csv(f'../tables/probability_tables/Chloramphenicol_cond_pos.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
