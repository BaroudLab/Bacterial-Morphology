{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import reduce\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Folder='PredictedLabelsTables/'\n",
    "\n",
    "paths=glob.glob(f'{Folder}*_trained.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_cooc_cond_prob(data):\n",
    "    \"\"\"\n",
    "    Compute all 8 co-occurrence probabilities for 3 binary classes. Given the zero class is positive\n",
    "    Uses chmod-like indexing: C=4, R=2, F=1\n",
    "    \"\"\"\n",
    "    mask = data[:, 0] == 1  # Condition\n",
    "    conditioned_data = data[mask][:, 1:]  # Only C, R, F where D == 1\n",
    "    n_samples = len(conditioned_data)\n",
    "    \n",
    "    probabilities = {}\n",
    "    \n",
    "    for combo in product([0, 1], repeat=3):\n",
    "        index = combo[0] * 4 + combo[1] * 2 + combo[2] * 1\n",
    "        \n",
    "        if n_samples == 0:\n",
    "            # Return NaN values but keep same structure\n",
    "            probabilities[index] = {\n",
    "                'combination': combo,\n",
    "                'count': np.nan,\n",
    "                'probability': np.nan,\n",
    "                'label': f\"{'C' if combo[0] else '¬C'}{'R' if combo[1] else '¬R'}{'F' if combo[2] else '¬F'}\"\n",
    "            }\n",
    "        else:\n",
    "            match = np.all(conditioned_data == combo, axis=1)\n",
    "            count = np.sum(match)\n",
    "            probability = count / n_samples\n",
    "            probabilities[index] = {\n",
    "                'combination': combo,\n",
    "                'count': count,\n",
    "                'probability': probability,\n",
    "                'label': f\"{'C' if combo[0] else '¬C'}{'R' if combo[1] else '¬R'}{'F' if combo[2] else '¬F'}\"\n",
    "            }\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cooccurance_dataframe(path,save_folder):\n",
    "    data = pd.read_csv(path,index_col=0)\n",
    "    data['n_cells_1']=data.n_cells_1.astype(int)\n",
    "    data['n_cells_2']=data.n_cells_2.astype(int)\n",
    "    \n",
    "\n",
    "    classes=['rods','filaments','planktonic','clumped']\n",
    "    for c in classes:\n",
    "        data[c]=data[c].astype(int)\n",
    "        \n",
    "    out=data.groupby('chip').apply(lambda x: calc_cooc_cond_prob(x[['positive','clumped','rods','filaments']].to_numpy()),include_groups=False)\n",
    "    chip_to_concentration = data.groupby('chip')['concentration'].first()\n",
    "\n",
    "    records = []\n",
    "    for chip, result_dict in out.items():\n",
    "        concentration = chip_to_concentration[chip]\n",
    "        for idx, entry in result_dict.items():\n",
    "            records.append({\n",
    "                'chip': chip,\n",
    "                'concentration': concentration,\n",
    "                'code': idx,\n",
    "                'C': entry['combination'][0],\n",
    "                'R': entry['combination'][1],\n",
    "                'F': entry['combination'][2],\n",
    "                'label': entry['label'],\n",
    "                'count': entry['count'],\n",
    "                'probability': entry['probability']\n",
    "            })\n",
    "\n",
    "    out_df = pd.DataFrame.from_records(records)\n",
    "    Filename=p.split('/')[1].split('_trained')[0]\n",
    "    out_df.to_csv(f'{save_folder}cooccurance_info_{Filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_folder='PredictedLabelsTables/'\n",
    "for p in paths:\n",
    "    generate_cooccurance_dataframe(p,save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Unify tables : warning overwrites provided data\n",
    "this creastes the table present in the github repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unionise_datasets(data, dates, date_index):\n",
    "    \"\"\"Combine datasets\"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for i, df in enumerate(data):\n",
    "        df_copy = df.copy()\n",
    "        df_copy['dataset'] = i\n",
    "        df_copy['date'] = dates[i]\n",
    "        df_copy['date_index'] = date_index[i]\n",
    "        result.append(df_copy)\n",
    "\n",
    "    out=pd.concat(result, ignore_index=True)\n",
    "    out = out.sort_values('concentration').reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Genta---------------------------------------------------------------------\n",
    "dates=['20221101','20221101','20230110','20230110'] # we add this metadata to keep track of the experiments\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221101-ecoli-genta1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221101-ecoli-genta2.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230110-e.coli-genta.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230110-e.coli-genta-2.csv',index_col=0))\n",
    "\n",
    "df=  unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Gentamicin_cooccurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Tetra---------------------------------------------------------------------\n",
    "dates=['20230315','20230315','20230404','20230404']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230315-ecoli_set-1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230315-ecoli_set-2.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230404-ecoli-Tetracycline_set1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230404-ecoli-Tetracycline_set2.csv',index_col=0))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Tetracycline_cooccurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Cipro---------------------------------------------------------------------\n",
    "dates=['20220531','20220531','20230131','20230131']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220531-MIC-e.coli-cipro_1stexp.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220531-MIC-e.coli-cipro_2ndexp.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230131-ecoli-cipro-1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230131-ecoli-cipro-2.csv',index_col=0))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Ciprofloxacin_cooccurance.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------AMP---------------------------------------------------------------------\n",
    "dates=['20220614','20220614']\n",
    "date_index=[1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220614-MIC-e.coli-amp-LB-1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220614-MIC-e.coli-amp-LB-2.csv',index_col=0))\n",
    "\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Ampicilin_cooccurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------CHP---------------------------------------------------------------------\n",
    "dates=['20220524','20220602','20220628','20220628','20221012','20221013','20221031','20221031','20221122','20230111','20230111','20230221','20230313','20230313']\n",
    "date_index=[1,1,1,2,1,1,1,2,1,1,2,1,1,2]\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220524-MIC-e.coli-chp-LB.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220602-MIC-e.coli-chp-LB.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220628-MIC-e.coli-chp-LB-1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220628-MIC-e.coli-chp-LB-2.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221012-ecoli-chp.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221013-ecoli-chp.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221031-ecoli-chp1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221031-ecoli-chp2.csv',index_col=0)) # A lot of empty wells which becomes positive (more than 50%) ==> Data not trustworthy for 0ug and 2ug, the rest all dead so we can't say much\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221122-ecoli-chp.csv',index_col=0))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230111-ecoli-chp.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230111-ecoli-chp-2.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230221-ecoli-chp-1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230313-ecoli-chp-1.csv',index_col=0))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230313-ecoli-chp-2.csv',index_col=0))\n",
    "\n",
    "df= unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'tables/probability_tables/Chloramphenicol_cooccurance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
