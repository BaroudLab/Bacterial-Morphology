{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281415c5-e2e0-4ba3-aedc-168e1840d491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import reduce\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2a6d85-79ca-4edb-807c-2f49c982d216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Folder='PredictedLabelsTables/'\n",
    "\n",
    "paths=glob.glob(f'{Folder}*_trained.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12d9ad8-36dc-45fd-ac62-4ecf0823d66f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_cooc_cond_prob(data):\n",
    "    \"\"\"\n",
    "    Compute all 8 co-occurrence probabilities for 3 binary classes. Given the zero class is positive\n",
    "    Uses chmod-like indexing: C=4, R=2, F=1\n",
    "    \"\"\"\n",
    "    mask = data[:, 0] == 1  # Condition\n",
    "    conditioned_data = data[mask][:, 1:]  # Only C, R, F where D == 1\n",
    "    n_samples = len(conditioned_data)\n",
    "    \n",
    "    probabilities = {}\n",
    "    \n",
    "    for combo in product([0, 1], repeat=3):\n",
    "        index = combo[0] * 4 + combo[1] * 2 + combo[2] * 1\n",
    "        \n",
    "        if n_samples == 0:\n",
    "            # Return NaN values but keep same structure\n",
    "            probabilities[index] = {\n",
    "                'combination': combo,\n",
    "                'count': np.nan,\n",
    "                'probability': np.nan,\n",
    "                'label': f\"{'C' if combo[0] else '¬C'}{'R' if combo[1] else '¬R'}{'F' if combo[2] else '¬F'}\"\n",
    "            }\n",
    "        else:\n",
    "            match = np.all(conditioned_data == combo, axis=1)\n",
    "            count = np.sum(match)\n",
    "            probability = count / n_samples\n",
    "            probabilities[index] = {\n",
    "                'combination': combo,\n",
    "                'count': count,\n",
    "                'probability': probability,\n",
    "                'label': f\"{'C' if combo[0] else '¬C'}{'R' if combo[1] else '¬R'}{'F' if combo[2] else '¬F'}\"\n",
    "            }\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a259c8-1b85-4e35-a10e-3c4cecea3866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cooccurance_dataframe(path,save_folder):\n",
    "    data = pd.read_csv(path,index_col=0)\n",
    "    data['n_cells_1']=data.n_cells_1.astype(int)\n",
    "    data['n_cells_2']=data.n_cells_2.astype(int)\n",
    "    \n",
    "\n",
    "    classes=['rods','filaments','planktonic','clumped']\n",
    "    for c in classes:\n",
    "        data[c]=data[c].astype(int)\n",
    "        \n",
    "    out=data.groupby('chip').apply(lambda x: calc_cooc_cond_prob(x[['positive','clumped','rods','filaments']].to_numpy()))\n",
    "    records = []\n",
    "    for chip, result_dict in out.items():\n",
    "        for idx, entry in result_dict.items():\n",
    "            records.append({\n",
    "                'chip': chip,\n",
    "                'code': idx,\n",
    "                'C': entry['combination'][0],\n",
    "                'R': entry['combination'][1],\n",
    "                'F': entry['combination'][2],\n",
    "                'label': entry['label'],\n",
    "                'count': entry['count'],\n",
    "                'probability': entry['probability']\n",
    "            })\n",
    "\n",
    "    out_df = pd.DataFrame.from_records(records)\n",
    "    Filename=p.split('/')[1].split('_trained')[0]\n",
    "    out_df.to_csv(f'{save_folder}cooccurance_info_{Filename}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4b03a01-4bdb-4f52-bf61-596b2d1267d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "save_folder='PredictedLabelsTables/'\n",
    "for p in paths:\n",
    "    generate_cooccurance_dataframe(p,save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4217f43-cf40-46ce-bdc0-22d6fce29bde",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Unify tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad9ee831-e3cd-4a65-8382-29833f470690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unionise_datasets(data, dates, date_index):\n",
    "    \"\"\"Combine datasets\"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for i, df in enumerate(data):\n",
    "        df_copy = df.copy()\n",
    "        df_copy['dataset'] = i\n",
    "        df_copy['date'] = dates[i]\n",
    "        df_copy['date_index'] = date_index[i]\n",
    "        result.append(df_copy)\n",
    "    \n",
    "    return pd.concat(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44256b-73c1-4b13-b0d4-2baf8bd1c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Genta---------------------------------------------------------------------\n",
    "dates=['20221101','20221101','20230110','20230110'] # we add this metadata to keep track of the experiments\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221101-ecoli-genta1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221101-ecoli-genta2.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230110-e.coli-genta.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230110-e.coli-genta-2.csv'))\n",
    "\n",
    "df=  unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Gentamicin_cooccurance.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38002f48-5da9-4e06-83be-5ceba90aa65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Tetra---------------------------------------------------------------------\n",
    "dates=['20230315','20230315','20230404','20230404']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230315-ecoli_set-1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230315-ecoli_set-2.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230404-ecoli-Tetracycline_set1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230404-ecoli-Tetracycline_set2.csv'))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Tetracycline_cooccurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5ced4-2992-483a-b81b-003f83975b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Cipro---------------------------------------------------------------------\n",
    "dates=['20220531','20220531','20230131','20230131']\n",
    "date_index=[1,2,1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220531-MIC-e.coli-cipro-1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220531-MIC-e.coli-cipro-2.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230131-ecoli-cipro-1stexp.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230131-ecoli-cipro-2ndexp.csv'))\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Ciprofloxacin_cooccurance.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f25056-016f-492b-9343-162fa1e2f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------AMP---------------------------------------------------------------------\n",
    "dates=['20220614','20220614']\n",
    "date_index=[1,2]\n",
    "\n",
    "data=[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220614-MIC-e.coli-amp-LB-1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220614-MIC-e.coli-amp-LB-2.csv'))\n",
    "\n",
    "\n",
    "df=unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Ampicilin_cooccurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00c519-06ab-4b16-b055-f31fe2886152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------CHP---------------------------------------------------------------------\n",
    "dates=['20220524','20220602','20220628','20220628','20221012','20221013','20221031','20221031','20221122','20230111','20230111','20230221','20230313','20230313']\n",
    "date_index=[1,1,1,2,1,1,1,2,1,1,2,1,1,2]\n",
    "\n",
    "data =[]\n",
    "\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220524-MIC-e.coli-chp-LB.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220602-MIC-e.coli-chp-LB.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220628-MIC-e.coli-chp-LB-1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20220628-MIC-e.coli-chp-LB-2.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221012-ecoli-chp.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221013-ecoli-chp.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221031-ecoli-chp1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221031-ecoli-chp2.csv')) # A lot of empty wells which becomes positive (more than 50%) ==> Data not trustworthy for 0ug and 2ug, the rest all dead so we can't say much\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20221122-ecoli-chp.csv'))\n",
    "\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230111-ecoli-chp.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230111-ecoli-chp-2.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230221-ecoli-chp-1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230313-ecoli-chp-1.csv'))\n",
    "data.append(pd.read_csv(f'{Folder}cooccurance_info_20230313-ecoli-chp-2.csv'))\n",
    "\n",
    "df= unionise_datasets(data,dates,date_index)\n",
    "df.to_csv(f'../tables/probability_tables/Chloramphenicol_cooccurance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
