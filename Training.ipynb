{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import ResNet34_Weights\n",
    "from IPython.display import display # to display images\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "plt.rcdefaults()  # Reset matplotlib settings to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BacteriaEndPointDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.info_table= pd.read_csv(csv_file) # we we load and suppres the loading of the indexing by index_col=0 our indices don't match!\n",
    "        self.info_table.drop(columns=['Unnamed: 0'],inplace=True) \n",
    "        self.ids= self.info_table.index.values\n",
    "\n",
    "        self.train_ids=[]\n",
    "        self.val_ids=[]\n",
    "        self.test_ids=[]\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.mode='train'\n",
    "        \n",
    "    def __len__(self):\n",
    "        if( self.mode =='train'):\n",
    "            return len(self.train_ids) # number of elements\n",
    "        elif(self.mode=='val'):\n",
    "            return len(self.val_ids) # number of elements\n",
    "        else:   #test \n",
    "            return len(self.test_ids) # number of elements\n",
    "\n",
    "\n",
    "    def train_val_split(self,split_div=3):\n",
    "        # split percentages can be adapted\n",
    "    \n",
    "        self.val_ids=np.random.choice(self.ids,size=len(self.ids)//split_div,replace=False)\n",
    "        self.train_ids=np.array([x for x in self.ids if x not in self.val_ids]) # not already choosen\n",
    "    \n",
    "        \n",
    "    def __getitem__(self, idx): \n",
    "        '''\n",
    "        loads image and labels into sample\n",
    "        warning: I use global indices so they match the indices in the table! Hence once needs to use iloc.\n",
    "        '''\n",
    "        if(self.mode =='train'):\n",
    "            global_idx=self.train_ids[idx]\n",
    "        elif(self.mode=='val'):\n",
    "            global_idx=self.val_ids[idx]\n",
    "        else: #test\n",
    "            global_idx=self.test_ids[idx]\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir,self.info_table.iloc[global_idx, 0])\n",
    "        image=Image.open(img_name)\n",
    "\n",
    "        labels = self.info_table.iloc[global_idx, 1:].values\n",
    "        labels = labels.astype('float')\n",
    "    \n",
    "        \n",
    "        if self.transform:\n",
    "            sample={'image': self.transform[self.mode](image), 'labels': labels,'global_id':global_idx}\n",
    "        else:\n",
    "            sample = {'image': image, 'labels': labels,'globel_id':global_idx}\n",
    "\n",
    "        return sample  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(3),  #resnet requirement\n",
    "        transforms.Resize(224), #resnet requirement\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),  #resnet requirement, but scales also to [0,1]\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])   #resnet requirement\n",
    "    ]),\n",
    "    'val':transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Datasets \n",
    "\n",
    "Crops are precomuted and stored as tifs for faster performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first entry is the table of the labeled set used for training\n",
    "# second enty is the path to the crops used in training\n",
    "data_set=BacteriaEndPointDataset('tables/LabelingSetAll.csv','Crops/',data_transforms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_set.train_val_split(3) # internally split, otherwise Dataloader will fail currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader=DataLoader(data_set,shuffle=True,batch_size=32,drop_last=True) # drops incomplete sets that don't match batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_set.mode='val'\n",
    "\n",
    "labels_val = []\n",
    "labels_train = []\n",
    "\n",
    "for i,D in enumerate(dataloader):\n",
    "    labels_val.append(D['labels'])\n",
    "\n",
    "data_set.mode='train'\n",
    "\n",
    "for i,D in enumerate(dataloader):\n",
    "    labels_train.append(D['labels'])\n",
    "      \n",
    "\n",
    "labels_val=np.concatenate(labels_val, axis=0)\n",
    "labels_train=np.concatenate(labels_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.bincount(np.all(labels_train==0,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.bincount(np.all(labels_val==0,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes=['positive','planktonic','clumped','rods','filaments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to get an idea, proper plots are in notebook Figure 4\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20, 10), dpi=200)\n",
    "ax[1].pie(labels_val.sum(axis=0), labels=classes, autopct='%1.0f%%')\n",
    "ax[1].set_title('validation')\n",
    "ax[0].pie(labels_train.sum(axis=0), labels=classes, autopct='%1.0f%%')\n",
    "ax[0].set_title('train')\n",
    "\n",
    "plt.rcParams.update({'font.size': 30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg=pd.DataFrame({'labels_train':labels_train.sum(axis=0),'N_train': labels_train.shape[0] * np.ones_like(labels_train.sum(axis=0)),'labels_val':labels_val.sum(axis=0),'N_val': labels_val.shape[0] * np.ones_like(labels_val.sum(axis=0))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg.to_csv('tables/LabelSplitInfoAll.csv') # save for later use: warning overwrites provided data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define model and run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "num_classes=5\n",
    "model = torchvision.models.resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "model.fc = torch.nn.Linear(512, num_classes) # affine linear transformation for last layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.00001) #my default 0.0001\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=50) #step_size25\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model and store metrics\n",
    "epoch_train_losses=[]\n",
    "epoch_val_losses=[]\n",
    "\n",
    "epoch_train_accuracy=[]\n",
    "epoch_val_accuracy=[]\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses=[]\n",
    "    train_accuracy=[]\n",
    "    train_precision=[]\n",
    "    train_recall=[]\n",
    "\n",
    "    data_set.mode='train'\n",
    "    model.train()\n",
    "    for D in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        data=D['image'].to(device)\n",
    "        labels=D['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #collect performance metrics\n",
    "        train_losses.append(loss.item())\n",
    "        prob=1/(1+ np.exp(-predictions.detach().numpy())) #sigmoid to get probability\n",
    "        threshold=0.5\n",
    "        y_pred=np.zeros_like(prob)\n",
    "        y_pred[prob>threshold]=1\n",
    "\n",
    "        train_accuracy.append(accuracy_score(labels,y_pred))\n",
    "\n",
    "    epoch_train_losses.append(np.mean(train_losses))  \n",
    "    epoch_train_accuracy.append(np.mean(train_accuracy))  \n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "#----validation--------------------------\n",
    "    val_losses=[]\n",
    "    val_accuracy=[]\n",
    "    val_precision=[]\n",
    "    val_recall=[]\n",
    "\n",
    "    data_set.mode='val'\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for D in dataloader:\n",
    "            data=D['image'].to(device)\n",
    "            labels=D['labels'].to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_losses.append(loss.item())\n",
    "             \n",
    "            prob=1/(1+ np.exp(-predictions.detach().numpy())) #sigmoid to get probability\n",
    "            threshold=0.5\n",
    "            y_pred=np.zeros_like(prob)\n",
    "            y_pred[prob>threshold]=1\n",
    "\n",
    "            val_accuracy.append(accuracy_score(labels,y_pred))\n",
    "  \n",
    "    epoch_val_losses.append(np.mean(val_losses))  \n",
    "    epoch_val_accuracy.append(np.mean(val_accuracy))  \n",
    "    \n",
    "    print(f' Trained {epoch} with average loss {np.mean(train_losses)}, {np.mean(val_losses)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg=pd.DataFrame({'train_losses':np.array(epoch_train_losses),'val_losses': np.array(epoch_val_losses),\n",
    "                 'train_acc': np.array(epoch_train_accuracy),'val_acc': np.array(epoch_val_accuracy)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg.to_csv('tables/TrainingInfo_All.csv')  # save for later use: warning overwrites provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to get an idea, proper plots are in notebook Figure 4\n",
    "\n",
    "fig= plt.figure(figsize=(5,5))\n",
    "ax=plt.gca()\n",
    "\n",
    "ax.plot(epoch_train_losses, color = 'red', label = 'train')\n",
    "ax.plot(epoch_val_losses, color = 'blue', label = 'val')\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('average loss per epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to get an idea, proper plots are in notebook Figure 4\n",
    "\n",
    "fig= plt.figure(figsize=(5,5))\n",
    "ax=plt.gca()\n",
    "\n",
    "ax.plot(epoch_train_accuracy, color = 'red', label = 'train')\n",
    "ax.plot(epoch_val_accuracy, color = 'blue', label = 'val')\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('average accuracy per epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_set.mode='val'\n",
    "\n",
    "pred_logit = []\n",
    "y_true = []\n",
    "id_list=[]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,D in enumerate(dataloader):\n",
    "        data=D['image'].to(device)\n",
    "        labels=D['labels'].to(device)\n",
    "        pred_logit.append(model(data))\n",
    "        y_true.append(labels)\n",
    "        id_list.append(D['global_id'].to(device))\n",
    "\n",
    "y_true=np.concatenate(y_true, axis=0)\n",
    "id_list=np.concatenate(id_list, axis=0)           \n",
    "\n",
    "pred_logit=np.concatenate(pred_logit, axis=0) \n",
    "prob=1/(1+ np.exp(-pred_logit)) #sigmoid to get probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg=pd.DataFrame({'pred_logit_0':pred_logit[:,0],'pred_logit_1':pred_logit[:,1],'pred_logit_2':pred_logit[:,2],'pred_logit_3':pred_logit[:,3],'pred_logit_4':pred_logit[:,4],'id_list':id_list,'positive':y_true[:,0],'rods': y_true[:,1],'planktonic':y_true[:,2],'filaments':y_true[:,3],'clumped':y_true[:,4]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg.to_csv('tables/ValidationPredictions_All.csv')# save for later use: warning overwrites provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes=['positive','planktonic','clumped','rods','filaments'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# illustrate logits : additional plot to evaluate training\n",
    "x=np.arange(-5,5,0.1)\n",
    "fig, axs = plt.subplots(1, len(classes), figsize=[15, 4.5] )\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.scatter(pred_logit[:,i],y_true[:,i])\n",
    "    ax.plot(x,1/(1+ np.exp(-x)),color='r')\n",
    "    ax.plot([0,0],[0,1],color='gray')\n",
    "    ax.set_title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## precision and recall calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "y_pred=np.zeros_like(prob)\n",
    "y_pred[prob>threshold]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision=precision_score(y_true,y_pred,average=None)\n",
    "recall=recall_score(y_true,y_pred,average=None)\n",
    "F1score=2 * precision*recall/(precision+recall)\n",
    "\n",
    "# precision true_positve/(true_positve + false_positive)  how many of prediced class labels are correct ?\n",
    "# -> The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "#recall : true_positve/(true_positve + false_negative) : how well is this class detected ?\n",
    "#->  The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg=pd.DataFrame({'precision': precision,'recall': recall,'F1score': F1score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg.to_csv('tables/Scores_All.csv') # save for later use: warning overwrites provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## to get an idea, proper plots are in notebook Figure 4\n",
    "\n",
    "fig= plt.figure()\n",
    "\n",
    "plt.scatter(classes,precision,label='precision')\n",
    "plt.scatter(classes,recall,label='recall')\n",
    "plt.scatter(classes,F1score,label='F1')\n",
    "\n",
    "plt.legend()\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualise examples\n",
    "\n",
    "The idea is to look at the logits and identify  images of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('tables/LabelingSetAll.csv')\n",
    "path='Crops/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(-5,5,0.1)\n",
    "fig, axs = plt.subplots(1, len(classes), figsize=[15, 4.5] )\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.scatter(pred_logit[:,i],y_true[:,i])\n",
    "    ax.plot(x,1/(1+ np.exp(-x)),color='r')\n",
    "    ax.plot([0,0],[0,1],color='gray')\n",
    "    ax.set_title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index=3\n",
    "# examples with low logit but positive: \n",
    "select_thres=-1\n",
    "indices_fneg= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==1) & (pred_logit[i,class_index]<=select_thres)]\n",
    "indices_tneg= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==0) & (pred_logit[i,class_index]<=select_thres)]\n",
    "\n",
    "# examples with high logit but negative\n",
    "select_thres=1\n",
    "indices_fpos= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==0) & (pred_logit[i,class_index]>=select_thres)]\n",
    "indices_tpos= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==1) & (pred_logit[i,class_index]>=select_thres)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=2\n",
    "col=[indices_fneg[I],indices_tneg[I],indices_fpos[I],indices_tpos[I]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:\n",
    "\n",
    "    fig = plt.figure()\n",
    "    image=Image.open(os.path.join(path,df.iloc[id_list[i], 1]))\n",
    "    display(image)\n",
    "    print(df.iloc[id_list[i],1:])\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## False positve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices_fpos:\n",
    "\n",
    "    fig = plt.figure()\n",
    "    image=Image.open(os.path.join(path,df.iloc[id_list[i], 1]))\n",
    "    display(image)\n",
    "    print(df.iloc[id_list[i],1:])\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices_fneg:\n",
    "\n",
    "    fig = plt.figure()\n",
    "    image=Image.open(os.path.join(path,df.iloc[id_list[i], 1]))\n",
    "    display(image)\n",
    "    print(df.iloc[id_list[i],1:])\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'trained_networks/'\n",
    "modelname = 'bacteria_trained_model_resnet34'\n",
    "os.makedirs('trained_networks', exist_ok=True) # creates folder to store the weights if it does not exist\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, modelname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
