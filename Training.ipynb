{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1dcabbd-b273-4007-9060-33075b764735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import ResNet34_Weights\n",
    "from IPython.display import display # to display images\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fe2b9e-c7c6-4ca7-8330-9fd5a782e052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BacteriaEndPointDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.info_table= pd.read_csv(csv_file) # we we load and suppres the loading of the indexing by index_col=0 our indices don't match!\n",
    "        self.info_table.drop(columns=['Unnamed: 0'],inplace=True) \n",
    "        self.ids= self.info_table.index.values\n",
    "\n",
    "        self.train_ids=[]\n",
    "        self.val_ids=[]\n",
    "        self.test_ids=[]\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.mode='train'\n",
    "        \n",
    "    def __len__(self):\n",
    "        if( self.mode =='train'):\n",
    "            return len(self.train_ids) # number of elements\n",
    "        elif(self.mode=='val'):\n",
    "            return len(self.val_ids) # number of elements\n",
    "        else:   #test \n",
    "            return len(self.test_ids) # number of elements\n",
    "\n",
    "\n",
    "    def train_val_split(self,split_div=3):\n",
    "        # split percentages can be adapted\n",
    "    \n",
    "        self.val_ids=np.random.choice(self.ids,size=len(self.ids)//split_div,replace=False)\n",
    "        self.train_ids=np.array([x for x in self.ids if x not in self.val_ids]) # not already choosen\n",
    "    \n",
    "        \n",
    "    def __getitem__(self, idx): \n",
    "        '''\n",
    "        loads image and labels into sample\n",
    "        warning: I use global indices so they match the indices in the table! Hence once needs to use iloc.\n",
    "        '''\n",
    "        if(self.mode =='train'):\n",
    "            global_idx=self.train_ids[idx]\n",
    "        elif(self.mode=='val'):\n",
    "            global_idx=self.val_ids[idx]\n",
    "        else: #test\n",
    "            global_idx=self.test_ids[idx]\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir,self.info_table.iloc[global_idx, 0])\n",
    "        image=Image.open(img_name)\n",
    "\n",
    "        labels = self.info_table.iloc[global_idx, 1:].values\n",
    "        labels = labels.astype('float')\n",
    "    \n",
    "        \n",
    "        if self.transform:\n",
    "            sample={'image': self.transform[self.mode](image), 'labels': labels,'global_id':global_idx}\n",
    "        else:\n",
    "            sample = {'image': image, 'labels': labels,'globel_id':global_idx}\n",
    "\n",
    "        return sample  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f806dcc-817b-4f95-a28f-c01b13b36a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(3),  #resnet requirement\n",
    "        transforms.Resize(224), #resnet requirement\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),  #resnet requirement, but scales also to [0,1]\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])   #resnet requirement\n",
    "    ]),\n",
    "    'val':transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d6147-71be-446e-85b4-1e5c67197909",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Datasets \n",
    "\n",
    "Crops are precomuted and stored as tifs for faster performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c1254-e0dc-4f76-b678-5b848d07bd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_set=BacteriaEndPointDataset('LabelingSetAll.csv','Crops/',data_transforms) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e1a30-013a-4e01-965c-e14371bfdbeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_set.train_val_split(3) # internally split, otherwise Dataloader will fail currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a23780-c90b-4dce-bb71-880bede1ee64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader=DataLoader(data_set,shuffle=True,batch_size=32,drop_last=True) # drops incomplete sets that don't match batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6c6b8-2ac8-49f8-8ae8-77000fbd29e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_set.mode='val'\n",
    "\n",
    "labels_val = []\n",
    "labels_train = []\n",
    "\n",
    "for i,D in enumerate(dataloader):\n",
    "    labels_val.append(D['labels'])\n",
    "\n",
    "data_set.mode='train'\n",
    "\n",
    "for i,D in enumerate(dataloader):\n",
    "    labels_train.append(D['labels'])\n",
    "      \n",
    "\n",
    "labels_val=np.concatenate(labels_val, axis=0)\n",
    "labels_train=np.concatenate(labels_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d659c-a518-4b94-93ea-fbad0ed9ee74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.bincount(np.all(labels_train==0,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ff641-3c7c-4017-ada9-830f14247429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.bincount(np.all(labels_val==0,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ceba1e-e027-413c-ad13-52ade0bf16ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes=['positive','planktonic','clumped','rods','filaments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aede7f-c4f7-48b5-9db5-fa8265ffa7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20, 10), dpi=200)\n",
    "ax[1].pie(labels_val.sum(axis=0), labels=classes, autopct='%1.0f%%')\n",
    "ax[1].set_title('validation')\n",
    "ax[0].pie(labels_train.sum(axis=0), labels=classes, autopct='%1.0f%%')\n",
    "ax[0].set_title('train')\n",
    "\n",
    "plt.rcParams.update({'font.size': 30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323c849-06bc-4f80-b486-b91f66e5b932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dg=pd.DataFrame({'labels_train':labels_train.sum(axis=0),'N_train': labels_train.shape[0] * np.ones_like(labels_train.sum(axis=0)),'labels_val':labels_val.sum(axis=0),'N_val': labels_val.shape[0] * np.ones_like(labels_val.sum(axis=0))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb32a1-cb51-4fc4-8375-543a1b1d101a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dg.to_csv('LabelSplitInfoAll.csv') # save for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff61620-5f22-4f5c-8849-c2121d856a94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define model and run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f32898-8941-4736-8366-0135cc722331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /Users/erikmaikranz/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83.3M/83.3M [00:01<00:00, 46.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "num_classes=5\n",
    "model = torchvision.models.resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "model.fc = torch.nn.Linear(512, num_classes) # affine linear transformation for last layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78508cf2-6361-44c1-bb94-db326e022ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.00001) #my default 0.0001\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=50) #step_size25\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fec75d-fac0-4f92-8e67-066a49f70d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model and store metrics\n",
    "epoch_train_losses=[]\n",
    "epoch_val_losses=[]\n",
    "\n",
    "epoch_train_accuracy=[]\n",
    "epoch_val_accuracy=[]\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses=[]\n",
    "    train_accuracy=[]\n",
    "    train_precision=[]\n",
    "    train_recall=[]\n",
    "\n",
    "    data_set.mode='train'\n",
    "    model.train()\n",
    "    for D in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        data=D['image'].to(device)\n",
    "        labels=D['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #collect performance metrics\n",
    "        train_losses.append(loss.item())\n",
    "        prob=1/(1+ np.exp(-predictions.detach().numpy())) #sigmoid to get probability\n",
    "        threshold=0.5\n",
    "        y_pred=np.zeros_like(prob)\n",
    "        y_pred[prob>threshold]=1\n",
    "\n",
    "        train_accuracy.append(accuracy_score(labels,y_pred))\n",
    "\n",
    "    epoch_train_losses.append(np.mean(train_losses))  \n",
    "    epoch_train_accuracy.append(np.mean(train_accuracy))  \n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "#----validation--------------------------\n",
    "    val_losses=[]\n",
    "    val_accuracy=[]\n",
    "    val_precision=[]\n",
    "    val_recall=[]\n",
    "\n",
    "    data_set.mode='val'\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for D in dataloader:\n",
    "            data=D['image'].to(device)\n",
    "            labels=D['labels'].to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_losses.append(loss.item())\n",
    "             \n",
    "            prob=1/(1+ np.exp(-predictions.detach().numpy())) #sigmoid to get probability\n",
    "            threshold=0.5\n",
    "            y_pred=np.zeros_like(prob)\n",
    "            y_pred[prob>threshold]=1\n",
    "\n",
    "            val_accuracy.append(accuracy_score(labels,y_pred))\n",
    "  \n",
    "    epoch_val_losses.append(np.mean(val_losses))  \n",
    "    epoch_val_accuracy.append(np.mean(val_accuracy))  \n",
    "    \n",
    "    print(f' Trained {epoch} with average loss {np.mean(train_losses)}, {np.mean(val_losses)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a695d9-0b84-47cc-8d4e-45cc181e1fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg=pd.DataFrame({'train_losses':np.array(epoch_train_losses),'val_losses': np.array(epoch_val_losses),\n",
    "                 'train_acc': np.array(epoch_train_accuracy),'val_acc': np.array(epoch_val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d768f89-faac-4624-969e-bca8e5ac341f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg.to_csv('TrainingInfo_All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69282db-8921-4409-8216-b780295b5f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initial visualisation: proper visualisation in a different notebook\n",
    "\n",
    "fig= plt.figure()\n",
    "ax=plt.gca()\n",
    "\n",
    "ax.plot(epoch_train_losses, color = 'red', label = 'train')\n",
    "ax.plot(epoch_val_losses, color = 'blue', label = 'val')\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('average loss per epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d2208-bbbf-4164-84a5-9d1afe8f3262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig= plt.figure()\n",
    "ax=plt.gca()\n",
    "\n",
    "ax.plot(epoch_train_accuracy, color = 'red', label = 'train')\n",
    "ax.plot(epoch_val_accuracy, color = 'blue', label = 'val')\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('average accuracy per epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902a938-10fa-48f8-9b0c-8677a3fb6be1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7af8da-b59c-4b54-a6cb-5c1a109c31e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_set.mode='val'\n",
    "\n",
    "pred_logit = []\n",
    "y_true = []\n",
    "id_list=[]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,D in enumerate(dataloader):\n",
    "        data=D['image'].to(device)\n",
    "        labels=D['labels'].to(device)\n",
    "        pred_logit.append(model(data))\n",
    "        y_true.append(labels)\n",
    "        id_list.append(D['global_id'].to(device))\n",
    "\n",
    "y_true=np.concatenate(y_true, axis=0)\n",
    "id_list=np.concatenate(id_list, axis=0)           \n",
    "\n",
    "pred_logit=np.concatenate(pred_logit, axis=0) \n",
    "prob=1/(1+ np.exp(-pred_logit)) #sigmoid to get probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc326c5-4f72-482b-a345-181b0ae54b38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg=pd.DataFrame({'pred_logit_0':pred_logit[:,0],'pred_logit_1':pred_logit[:,1],'pred_logit_2':pred_logit[:,2],'pred_logit_3':pred_logit[:,3],'pred_logit_4':pred_logit[:,4],'id_list':id_list,'positive':y_true[:,0],'rods': y_true[:,1],'planktonic':y_true[:,2],'filaments':y_true[:,3],'clumped':y_true[:,4]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b1893-7b7a-4890-b3f4-f6c366ee1155",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg.to_csv('ValidationPredictions_All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5aa6e-c5f1-4f3e-91b7-df65d1ae94f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes=['positive','planktonic','clumped','rods','filaments'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf0cc2-fd6e-4d4d-9b5f-cf9b3e1d7a9c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# illustrate logits\n",
    "x=np.arange(-5,5,0.1)\n",
    "fig, axs = plt.subplots(1, len(classes), figsize=[15, 4.5] )\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.scatter(pred_logit[:,i],y_true[:,i])\n",
    "    ax.plot(x,1/(1+ np.exp(-x)),color='r')\n",
    "    ax.plot([0,0],[0,1],color='gray')\n",
    "    ax.set_title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288e68c-a1d8-488e-b781-42a5906bbc1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## precision and recall calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31ea2d-8032-483d-a646-96c51103dde1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "y_pred=np.zeros_like(prob)\n",
    "y_pred[prob>threshold]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821ccc9-c3fc-4bda-9c21-ac75e06e161f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision=precision_score(y_true,y_pred,average=None)\n",
    "recall=recall_score(y_true,y_pred,average=None)\n",
    "F1score=2 * precision*recall/(precision+recall)\n",
    "\n",
    "# precision true_positve/(true_positve + false_positive)  how many of prediced class labels are correct ?\n",
    "# -> The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "#recall : true_positve/(true_positve + false_negative) : how well is this class detected ?\n",
    "#->  The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf10ec5-35e2-48f9-a922-b86cc1a5f770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg=pd.DataFrame({'precision': precision,'recall': recall,'F1score': F1score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9aae2-99bb-4063-add0-ebbb6603fde3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dg.to_csv('Scores_All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1d477-7d4c-4ca6-9695-5f1eaa814ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Illustrate\n",
    "fig= plt.figure()\n",
    "\n",
    "plt.scatter(classes,precision,label='precision')\n",
    "plt.scatter(classes,recall,label='recall')\n",
    "plt.scatter(classes,F1score,label='F1')\n",
    "\n",
    "plt.legend()\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b74e13-33fd-413c-bc2c-141469e6e2e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualise examples\n",
    "\n",
    "The idea is to look at the logits and identify  images of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41efdc-0c76-4384-8b68-1a2e71877b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('LabelingSetAll.csv')\n",
    "path='Crops/'\n",
    "#classes=['positive','rods','planktonic','filaments','clumped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac0f5d-f46d-4983-b5e0-e8e6520cb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(-5,5,0.1)\n",
    "fig, axs = plt.subplots(1, len(classes), figsize=[15, 4.5] )\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.scatter(pred_logit[:,i],y_true[:,i])\n",
    "    ax.plot(x,1/(1+ np.exp(-x)),color='r')\n",
    "    ax.plot([0,0],[0,1],color='gray')\n",
    "    ax.set_title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e5492-2192-491d-9c87-86769358cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index=3\n",
    "# examples with low logit but positive: \n",
    "select_thres=-1\n",
    "indices_fneg= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==1) & (pred_logit[i,class_index]<=select_thres)]\n",
    "indices_tneg= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==0) & (pred_logit[i,class_index]<=select_thres)]\n",
    "\n",
    "# examples with high logit but negative\n",
    "select_thres=1\n",
    "indices_fpos= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==0) & (pred_logit[i,class_index]>=select_thres)]\n",
    "indices_tpos= [i for i in range(len(y_true[:,class_index])) if (y_true[i,class_index]==1) & (pred_logit[i,class_index]>=select_thres)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59838f3f-4209-40c3-8fab-bfc183e81d45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227e8c1-1e8d-4ec4-ba22-b25cdc87e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=2\n",
    "col=[indices_fneg[I],indices_tneg[I],indices_fpos[I],indices_tpos[I]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b396956-60fd-4389-bc34-193269acd1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in col:\n",
    "\n",
    "    fig = plt.figure()\n",
    "    image=Image.open(os.path.join(path,df.iloc[id_list[i], 1]))\n",
    "    display(image)\n",
    "    print(df.iloc[id_list[i],1:])\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c87fa6-fc01-4774-9895-e983fa9837d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## False positve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae708a02-3b2b-459f-b125-2426d3a436ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices_fpos:\n",
    "\n",
    "    fig = plt.figure()\n",
    "    image=Image.open(os.path.join(path,df.iloc[id_list[i], 1]))\n",
    "    display(image)\n",
    "    print(df.iloc[id_list[i],1:])\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5a37d-6a22-46f4-8b2d-fe2b1e69639f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb52739-8415-43da-95aa-aeedb8d741f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices_fneg:\n",
    "\n",
    "    fig = plt.figure()\n",
    "    image=Image.open(os.path.join(path,df.iloc[id_list[i], 1]))\n",
    "    display(image)\n",
    "    print(df.iloc[id_list[i],1:])\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24467ee-a412-477f-98ea-97040a0f062f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d4f28-fd58-450b-ae01-74cbd90e22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004230e6-7a31-480e-ad4e-979b37356d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'trained_networks/'\n",
    "modelname = 'bacteria_trained_model_resnet34'\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, modelname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
